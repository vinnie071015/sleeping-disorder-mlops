# """
# SageMaker training script supporting 3 Course Models: LR, SVM, RF.
# Includes verbose debugging and environment checks.
# """
# import argparse
# import os
# import sys
# import joblib
# import pandas as pd
# import matplotlib.pyplot as plt
# import seaborn as sns
# from sklearn.model_selection import train_test_split
# from sklearn.linear_model import LogisticRegression
# from sklearn.svm import SVC
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder
# from sklearn.compose import ColumnTransformer
# from sklearn.pipeline import Pipeline
# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score

# try:
#     import wandb
# except ImportError:
#     wandb = None

# from src.data_processor import load_data, clean_data # <--- è·¯å¾„ä¿®å¤åŽçš„å¯¼å…¥

# # ... (parse_args, get_model, save_plot_confusion_matrix, perform_bias_audit å‡½æ•°ä¿æŒä¸å˜) ...

# def create_pipeline(categorical_features, numerical_features, n_estimators=None, C=None, kernel=None, model_type=None):
#     """
#     æž„å»º Scikit-learn Pipelineã€‚
#     (é‡æž„ï¼šå°† Pipeline é€»è¾‘ç§»åˆ°å‡½æ•°ä¸­ï¼Œæ–¹ä¾¿ä¸»å‡½æ•°ç˜¦èº«)
#     """
#     preprocessor = ColumnTransformer(
#         transformers=[
#             ('num', StandardScaler(), numerical_features),
#             ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
#         ]
#     )

#     model = get_model(argparse.Namespace(
#         model_type=model_type, n_estimators=n_estimators, C=C, kernel=kernel))
        
#     return Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])


# def main():
#     """ä¸»è®­ç»ƒæµç¨‹ (åŒ…å«äº†è¯¦ç»†çš„æ­¥éª¤æ‰“å°)"""
#     args = parse_args()
#     # --------------------------------------------------------
#     print("\nâœ… SCRIPT START: SageMaker å®¹å™¨çŽ¯å¢ƒå·²å°±ç»ªï¼Œå¼€å§‹æ‰§è¡Œ train.py ...") # ðŸ‘ˆ å¢žåŠ è¿™ä¸ªæ˜Žç¡®çš„ä¿¡å·
#     # --------------------------------------------------------
#     print("\n--- 1. çŽ¯å¢ƒè¯Šæ–­ä¸Žå‚æ•°æŽ¥æ”¶ (Receiving Instructions) ---")
    
#     # æ‰“å°å…³é”® SageMaker çŽ¯å¢ƒå˜é‡
#     print(f"ENV_DIAG: SM_CHANNEL_TRAINING = {os.environ.get('SM_CHANNEL_TRAINING')}")
#     print(f"ENV_DIAG: SM_MODEL_DIR = {os.environ.get('SM_MODEL_DIR')}")
    
#     # ä¿®å¤ Python æ¨¡å—å¯¼å…¥è·¯å¾„ (é‡å¤æ‰§è¡Œç¡®ä¿å®‰å…¨)
#     sys.path.append(os.getcwd()) 
    
#     print(f"PARAM_DIAG: Model Type: {args.model_type}, N_Estimators: {args.n_estimators}, C: {args.C}")
#     print("--------------------------------------------------------")
    
    
#     # --- 2. æ•°æ®åŠ è½½ä¸Žæ¸…æ´— ---
    
#     # ç¡®è®¤æ•°æ®åœ¨å®¹å™¨å†…çš„å®žé™…è·¯å¾„
#     data_dir_path = args.train
#     file_path = os.path.join(data_dir_path, "sleep_data.csv")
    
#     print(f"\n--- 2. Data Loading ---")
#     print(f"DATA_DIAG: Attempting to load file from: {file_path}")
    
#     try:
#         df = load_data(file_path)
#         df = clean_data(df)
#     except Exception as e:
#         # å¦‚æžœåŠ è½½æˆ–æ¸…æ´—å¤±è´¥ï¼Œæ‰“å°è‡ªå®šä¹‰é”™è¯¯å¹¶é€€å‡º
#         print(f"âŒ FATAL ERROR: Data loading/cleaning failed at runtime: {e}")
#         sys.exit(1) # å¼ºåˆ¶é€€å‡ºï¼Œé¿å…ç»§ç»­è¿è¡Œ
        

#     # --- 3. ç‰¹å¾å’Œç›®æ ‡å‡†å¤‡ ---
#     target_col = 'sleep_disorder'
#     df[target_col] = df[target_col].fillna('None')
    
#     le = LabelEncoder()
#     df[target_col] = le.fit_transform(df[target_col])
    
#     X = df.drop(columns=[target_col, 'person_id'])
#     y = df[target_col]
    
#     print(f"DATA_DIAG: Final Feature Count: {len(X.columns)}")
#     print(f"DATA_DIAG: Target Classes: {le.classes_}")
    
#     # --- 4. è®­ç»ƒä¸Žè¯„ä¼° ---
#     print(f"\n--- 4. Model Training ---")
    
#     cat_features = X.select_dtypes(include=['object']).columns
#     num_features = X.select_dtypes(include=['number']).columns

#     # ç»„è£… Pipeline (ä½¿ç”¨é‡æž„åŽçš„ create_pipeline å‡½æ•°)
#     pipeline = create_pipeline(
#         cat_features, num_features, args.n_estimators, args.C, args.kernel, args.model_type
#     )

#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
#     try:
#         print("STATUS: Fitting model to data...")
#         pipeline.fit(X_train, y_train)
#         print("STATUS: Model fitting completed.")
#     except Exception as e:
#         print(f"âŒ FATAL ERROR: Model fitting crashed: {e}")
#         sys.exit(1)


#     # --- 5. äº§ç‰©ç”Ÿæˆä¸Žä¿å­˜ ---
#     print("\n--- 5. Artifacts Generation ---")
#     y_pred = pipeline.predict(X_test)
#     accuracy = accuracy_score(y_test, y_pred)
    
#     print(f"RESULT: Accuracy: {accuracy:.4f}")
    
#     # Audits & Plots
#     save_plot_confusion_matrix(y_test, y_pred, args.model_dir)
#     perform_bias_audit(X_test, y_test, y_pred)
    
#     # Save Model
#     model_output_path = os.path.join(args.model_dir, "model.joblib")
#     joblib.dump(pipeline, model_output_path)
#     joblib.dump(le, os.path.join(args.model_dir, "label_encoder.joblib"))
#     print(f"âœ… FINAL STATUS: Model saved successfully to {args.model_dir}")


# if __name__ == '__main__':
#     main()

import os
import sys
import subprocess
import time
import boto3

# --- é…ç½®éƒ¨åˆ† ---
# è¿™é‡Œå®šä¹‰æˆ‘ä»¬è¦â€œæ‰‹åŠ¨â€å®‰è£…çš„é«˜é£Žé™©åº“
# å¼ºçƒˆå»ºè®®é”å®šç‰ˆæœ¬ï¼Œä»¥é¿å…æˆ‘ä»¬ä¹‹å‰æŽ¨æµ‹çš„å…¼å®¹æ€§é—®é¢˜
RISKY_PACKAGES = [
    "numpy==1.23.5",      # é”å®šæ—§ç‰ˆæœ¬ä»¥å…¼å®¹ SageMaker SKLearn å®¹å™¨
    "pandas==1.5.3",      # é”å®š 1.x ç‰ˆæœ¬
    "scikit-learn==1.2.2" # ä¸Žå®¹å™¨ç‰ˆæœ¬åŒ¹é…
]

# èŽ·å–ä»»åŠ¡åå’ŒåŒºåŸŸ
JOB_NAME = os.environ.get('TRAINING_JOB_NAME', f'debug-job-{int(time.time())}')
REGION = os.environ.get('AWS_REGION', 'us-east-1')
# å°è¯•ä»ŽçŽ¯å¢ƒå˜é‡èŽ·å– Bucketï¼Œå¦‚æžœæ²¡æœ‰åˆ™ç¡¬ç¼–ç æ‚¨çš„ Bucket
BUCKET_NAME = 'sleep-disorder-mlops-bucket' 

def upload_log_to_s3(content, filename_suffix):
    """ä¸Šä¼ æ—¥å¿—åˆ° S3 çš„è¾…åŠ©å‡½æ•°"""
    try:
        s3 = boto3.client('s3', region_name=REGION)
        s3_key = f'sagemaker-logs/manual-install-debug/{JOB_NAME}/{filename_suffix}.txt'
        s3.put_object(Bucket=BUCKET_NAME, Key=s3_key, Body=content.encode('utf-8'))
        print(f"--- âœ… [S3 UPLOAD] æ—¥å¿—å·²ä¸Šä¼ : s3://{BUCKET_NAME}/{s3_key} ---")
        return f"s3://{BUCKET_NAME}/{s3_key}"
    except Exception as e:
        print(f"--- âŒ [S3 ERROR] ä¸Šä¼ å¤±è´¥: {e} ---")
        return None

def install_risky_packages():
    """åœ¨è„šæœ¬å†…éƒ¨æ‰‹åŠ¨è¿è¡Œ pip install"""
    print(f"--- ðŸ› ï¸ [INSTALL] å¼€å§‹æ‰‹åŠ¨å®‰è£…åº“: {RISKY_PACKAGES} ---")
    
    cmd = [sys.executable, "-m", "pip", "install"] + RISKY_PACKAGES
    
    # æ‰§è¡Œå‘½ä»¤å¹¶æ•èŽ·æ‰€æœ‰è¾“å‡º
    result = subprocess.run(
        cmd,
        capture_output=True,
        text=True
    )
    
    # æ‹¼æŽ¥å®Œæ•´æ—¥å¿—
    full_log = (
        f"COMMAND: {' '.join(cmd)}\n"
        f"RETURN CODE: {result.returncode}\n\n"
        f"====== STDOUT ======\n{result.stdout}\n\n"
        f"====== STDERR ======\n{result.stderr}\n"
    )
    
    # æ— è®ºæˆåŠŸå¤±è´¥ï¼Œéƒ½ä¸Šä¼ æ—¥å¿—
    if result.returncode == 0:
        print("--- âœ… [INSTALL SUCCESS] æ‰‹åŠ¨å®‰è£…æˆåŠŸï¼---")
        upload_log_to_s3(full_log, "install_success_log")
        return True
    else:
        print("--- âŒ [INSTALL FAILED] æ‰‹åŠ¨å®‰è£…å¤±è´¥ï¼---")
        print(result.stderr[-500:]) # æ‰“å°æœ€åŽ500å­—ç¬¦åˆ°æŽ§åˆ¶å°(å¦‚æžœæœ‰çš„è¯)
        s3_path = upload_log_to_s3(full_log, "install_failure_log")
        print(f"è¯¦ç»†é”™è¯¯æ—¥å¿—è¯·æŸ¥çœ‹ S3: {s3_path}")
        return False

if __name__ == "__main__":
    print("--- ðŸš€ [START] User script started. Safe dependencies loaded. ---")
    
    # 1. å°è¯•å®‰è£…é«˜é£Žé™©åº“
    success = install_risky_packages()
    
    if not success:
        print("--- ðŸ’€ [ABORT] æ ¸å¿ƒåº“å®‰è£…å¤±è´¥ï¼Œè„šæœ¬é€€å‡ºã€‚ ---")
        # é€€å‡ºç  1 è®© SageMaker çŸ¥é“ä»»åŠ¡å¤±è´¥äº†
        sys.exit(1)
        
    # 2. å¦‚æžœå®‰è£…æˆåŠŸï¼Œå°è¯•å¯¼å…¥æµ‹è¯•
    try:
        import numpy as np
        import pandas as pd
        import sklearn
        print(f"--- âœ… [IMPORT TEST] Libraries imported successfully.")
        print(f"Numpy: {np.__version__}, Pandas: {pd.__version__}, Sklearn: {sklearn.__version__}")
        
        # ä¸Šä¼ ä¸€ä¸ªæœ€ç»ˆçš„æˆåŠŸæ ‡å¿—
        upload_log_to_s3("All systems go! Environment is ready.", "final_success")
        
    except ImportError as e:
        error_msg = f"Install reported success, but IMPORT failed: {e}"
        print(error_msg)
        upload_log_to_s3(error_msg, "import_error_log")
        sys.exit(1)

    # 3. æ¨¡æ‹Ÿæžç®€è®­ç»ƒ
    print("--- â³ [TRAINING] Simulating training loop... ---")
    time.sleep(5)
    print("âœ… Accuracy: 0.99")
    print("--- âœ… [DONE] Script finished. ---")