{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d38af7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/zhengchengsheng/Library/Application Support/sagemaker/config.yaml\n",
      "--- âš™ï¸ Step 1: Initializing SageMaker Environment ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name ML_Project to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ è­¦å‘Š: æ— æ³•è‡ªåŠ¨è·å–è§’è‰²ï¼Œè¯·æ‰‹åŠ¨å¡«å…¥ ARNã€‚\n",
      "âœ… Role: arn:aws:iam::137568342316:role/SageMakerExecutionRole\n",
      "âœ… Bucket: sleep-disorder-mlops-bucket\n",
      "âœ… Git Repo: https://github.com/vinnie071015/sleeping-disorder-mlops.git\n",
      "\n",
      "--- ğŸ’¾ Step 2: Defining S3 Data Input ---\n",
      "âœ… Training Data Source: s3://sleep-disorder-mlops-bucket/raw_data/\n",
      "\n",
      "--- ğŸ—ï¸ Step 3: Defining Common Estimator Configuration (Git Mode) ---\n",
      "âœ… Model Artifacts Output Path (FIXED): s3://sleep-disorder-mlops-bucket/sagemaker-tuning-output/\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'wandb_api_key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/py/wsw9dv2n5g70rl8sm3pxxjg40000gn/T/ipykernel_9704/1927004868.py\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;34m'output_path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_output_s3_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     'environment': {\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;34m'WANDB_API_KEY'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwandb_api_key\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# å®¹å™¨ä¼šè‡ªåŠ¨è¯»å–è¿™ä¸ªå˜é‡è¿›è¡Œç™»å½•\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;34m'WANDB_PROJECT'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'sleep-disorder-mlops'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# å¯é€‰ï¼šæŒ‡å®šé¡¹ç›®å\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;34m'WANDB_WATCH'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'false'\u001b[0m \u001b[0;31m# å¯é€‰ï¼šå…³é—­ä¸å¿…è¦çš„æ¨¡å‹ç›‘æ§ä»¥åŠ å¿«é€Ÿåº¦\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wandb_api_key' is not defined"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, CategoricalParameter, HyperparameterTuner\n",
    "from sagemaker import get_execution_role\n",
    "import os\n",
    "\n",
    "print(\"--- âš™ï¸ Step 1: Initializing SageMaker Environment ---\")\n",
    "\n",
    "# 1. è·å–æ‰§è¡Œè§’è‰² (IAM Role)\n",
    "# å¦‚æœåœ¨æœ¬åœ° VS Code è¿è¡Œï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨æŒ‡å®š Role ARN\n",
    "try:\n",
    "    role = get_execution_role()\n",
    "except ValueError:\n",
    "    print(\"âš ï¸ è­¦å‘Š: æ— æ³•è‡ªåŠ¨è·å–è§’è‰²ï¼Œè¯·æ‰‹åŠ¨å¡«å…¥ ARNã€‚\")\n",
    "    # è¯·å» AWS Console -> IAM -> Roles æ‰¾ä¸€ä¸ªç±»ä¼¼ AmazonSageMaker-ExecutionRole çš„è§’è‰²\n",
    "    role = \"arn:aws:iam::137568342316:role/SageMakerExecutionRole\" \n",
    "\n",
    "# 2. åŸºç¡€é…ç½®\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = 'sleep-disorder-mlops-bucket' # æ‚¨çš„ S3 æ¡¶å\n",
    "\n",
    "# 3. æŒ‡å®šä»£ç æº (Source of Truth for Code)\n",
    "# SageMaker ä¼šè‡ªåŠ¨ `git clone` è¿™ä¸ªä»“åº“åˆ°è®­ç»ƒå®ä¾‹ä¸­\n",
    "git_repo = 'https://github.com/vinnie071015/sleeping-disorder-mlops.git' # æ›¿æ¢ä¸ºæ‚¨çš„ä»“åº“åœ°å€\n",
    "git_config = {\n",
    "    'repo': git_repo, \n",
    "    'branch': 'main'\n",
    "}\n",
    "\n",
    "print(f\"âœ… Role: {role}\")\n",
    "print(f\"âœ… Bucket: {bucket_name}\")\n",
    "print(f\"âœ… Git Repo: {git_repo}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- ğŸ’¾ Step 2: Defining S3 Data Input ---\")\n",
    "\n",
    "# å®šä¹‰ S3 æ•°æ®è¾“å…¥\n",
    "# SageMaker ä¼šè‡ªåŠ¨æŠŠè¿™ä¸ª S3 è·¯å¾„ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ä¸‹è½½åˆ°å®¹å™¨å†…çš„ /opt/ml/input/data/train/\n",
    "# è¿™é‡Œçš„ s3_data å¿…é¡»æŒ‡å‘åŒ…å« sleep_data.csv çš„æ–‡ä»¶å¤¹è·¯å¾„ (ä»¥ / ç»“å°¾)\n",
    "s3_input_path = f's3://{bucket_name}/raw_data/'\n",
    "\n",
    "train_input = sagemaker.inputs.TrainingInput(\n",
    "    s3_data=s3_input_path, \n",
    "    content_type='text/csv'\n",
    ")\n",
    "\n",
    "print(f\"âœ… Training Data Source: {s3_input_path}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- ğŸ—ï¸ Step 3: Defining Common Estimator Configuration (Git Mode) ---\")\n",
    "\n",
    "# ä½¿ç”¨ ml.m5.large (é€šç”¨å‹)\n",
    "instance_type = 'ml.m5.large'\n",
    "\n",
    "# âš ï¸ å…³é”®ä¿®å¤ï¼šå®šä¹‰ S3 æ¨¡å‹è¾“å‡ºè·¯å¾„ï¼Œå¼ºåˆ¶ä½¿ç”¨ä½ çš„è‡ªå®šä¹‰æ¡¶\n",
    "model_output_s3_path = f's3://{bucket_name}/sagemaker-tuning-output/' \n",
    "print(f\"âœ… Model Artifacts Output Path (FIXED): {model_output_s3_path}\")\n",
    "\n",
    "\n",
    "common_estimator_args = {\n",
    "    # ä¿®æ­£ 1: å…¥å£æ–‡ä»¶è·¯å¾„è¦åŒ…å« src (å› ä¸º source_dir å˜æˆäº†æ ¹ç›®å½•)\n",
    "    'entry_point': 'src/train.py',\n",
    "    \n",
    "    # ä¿®æ­£ 2: source_dir è®¾ä¸º '.' (ä»£è¡¨ Git ä»“åº“çš„æ ¹ç›®å½•)\n",
    "    'source_dir': '.',\n",
    "    \n",
    "    'role': role,\n",
    "    'instance_count': 1,\n",
    "    'instance_type': instance_type,\n",
    "    'framework_version': '1.2-1',\n",
    "    'py_version': 'py3',\n",
    "    'git_config': git_config,\n",
    "    'sagemaker_session': sagemaker_session,\n",
    "    \n",
    "    # === å…³é”®ä¿®å¤ï¼šæ·»åŠ  output_path å‚æ•° ===\n",
    "    'output_path': model_output_s3_path,\n",
    "    'environment': {\n",
    "        'WANDB_API_KEY': \"0f759a15e3c54016f3f727c9720f0c9206fdd5c1\",  # å®¹å™¨ä¼šè‡ªåŠ¨è¯»å–è¿™ä¸ªå˜é‡è¿›è¡Œç™»å½•\n",
    "        'WANDB_PROJECT': 'sleep-disorder-mlops', # å¯é€‰ï¼šæŒ‡å®šé¡¹ç›®å\n",
    "        'WANDB_WATCH': 'false' # å¯é€‰ï¼šå…³é—­ä¸å¿…è¦çš„æ¨¡å‹ç›‘æ§ä»¥åŠ å¿«é€Ÿåº¦\n",
    "    }\n",
    "    # ========================================\n",
    "}\n",
    "\n",
    "print(f\"âœ… Instance Type: {instance_type}\")\n",
    "print(f\"âœ… Path Correction: source_dir='.', entry_point='src/train.py'\")\n",
    "\n",
    "\n",
    "print(\"\\n--- ğŸ›ï¸ Step 4: Defining Tuners for 3 Models ---\")\n",
    "\n",
    "# å®šä¹‰æŒ‡æ ‡æŠ“å–è§„åˆ™ (å¯¹åº” src/train.py ä¸­çš„ print è¯­å¥)\n",
    "metric_definitions = [\n",
    "    {'Name': 'accuracy', 'Regex': 'âœ… Accuracy: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'f1', 'Regex': 'âœ… F1 Score: ([0-9\\\\.]+)'}\n",
    "]\n",
    "\n",
    "# ==========================================\n",
    "# A. Random Forest Tuner\n",
    "# ==========================================\n",
    "# æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨çš„ common_estimator_args å·²ç»åŒ…å«äº† output_path\n",
    "rf_estimator = SKLearn(**common_estimator_args) \n",
    "# å›ºå®šæ¨¡å‹ç±»å‹ä¸º RF\n",
    "rf_estimator.set_hyperparameters(model_type='random_forest')\n",
    "\n",
    "rf_tuner = HyperparameterTuner(\n",
    "    estimator=rf_estimator,\n",
    "    objective_metric_name='accuracy',\n",
    "    metric_definitions=metric_definitions,\n",
    "    hyperparameter_ranges={\n",
    "        'n_estimators': IntegerParameter(50, 150),\n",
    "        'max_depth': IntegerParameter(5, 15)\n",
    "    },\n",
    "    max_jobs=2,          # æ€»å…±è·‘ 2 æ¬¡ (çœé’±)\n",
    "    max_parallel_jobs=1, # ä¸²è¡Œè·‘ (å®‰å…¨)\n",
    "    base_tuning_job_name='rf-tuning'\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# B. SVM Tuner\n",
    "# ==========================================\n",
    "svm_estimator = SKLearn(**common_estimator_args)\n",
    "svm_estimator.set_hyperparameters(model_type='svm')\n",
    "\n",
    "svm_tuner = HyperparameterTuner(\n",
    "    estimator=svm_estimator,\n",
    "    objective_metric_name='accuracy',\n",
    "    metric_definitions=metric_definitions,\n",
    "    hyperparameter_ranges={\n",
    "        'C': ContinuousParameter(0.1, 5.0),\n",
    "        'kernel': CategoricalParameter(['rbf', 'linear'])\n",
    "    },\n",
    "    max_jobs=2,\n",
    "    max_parallel_jobs=1,\n",
    "    base_tuning_job_name='svm-tuning'\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# C. Logistic Regression Tuner\n",
    "# ==========================================\n",
    "lr_estimator = SKLearn(**common_estimator_args)\n",
    "lr_estimator.set_hyperparameters(model_type='logistic_regression')\n",
    "\n",
    "lr_tuner = HyperparameterTuner(\n",
    "    estimator=lr_estimator,\n",
    "    objective_metric_name='accuracy',\n",
    "    metric_definitions=metric_definitions,\n",
    "    hyperparameter_ranges={\n",
    "        'C': ContinuousParameter(0.1, 5.0)\n",
    "    },\n",
    "    max_jobs=2,\n",
    "    max_parallel_jobs=1,\n",
    "    base_tuning_job_name='lr-tuning'\n",
    ")\n",
    "\n",
    "print(\"âœ… Tuners for RF, SVM, and LR are ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5061ccbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ğŸš€ Step 5: Launching Single Debug Job ---\n",
      "\n",
      "ğŸŒ² Launching Random Forest (Debug Mode: 1 Job)... (Timestamp: 19:08:12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '/var/folders/py/wsw9dv2n5g70rl8sm3pxxjg40000gn/T/tmppem1bg1l'...\n",
      "Already on 'main'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your branch is up to date with 'origin/main'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................................!\n",
      "âœ… Training Job Completed Successfully.\n",
      "\n",
      "\n",
      "â³ Waiting 10 seconds for S3 consistency...\n",
      "\n",
      "ğŸ” [Log Fetcher] Looking for logs in s3://sleep-disorder-mlops-bucket/debug_logs/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengchengsheng/opt/anaconda3/envs/mlops-env/lib/python3.9/site-packages/boto3/compat.py:84: PythonDeprecationWarning: Boto3 will no longer support Python 3.9 starting April 29, 2026. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.10 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ [Log Fetcher] Found latest log: debug_logs/train_failure_log_20251203_111130.txt (Last Modified: 2025-12-03 11:11:31+00:00)\n",
      "============================================================\n",
      "=== TRAINING SESSION STARTED: 2025-12-03 11:10:56.715676 ===\n",
      "--- ğŸš€ SCRIPT START ---\n",
      "INFO: Arguments: Namespace(model_type='\"random_forest\"', n_estimators=104, C=1.0, kernel='rbf', train='/opt/ml/input/data/train', model_dir='/opt/ml/model')\n",
      "INFO: Env SM_CHANNEL_TRAINING: None\n",
      "INFO: Effective Data Path: /opt/ml/input/data/train\n",
      "\n",
      "ğŸ“¦ [INIT] Start environment cleanup & installation...\n",
      "   --- Purging pre-installed libraries: ['numpy', 'pandas', 'scikit-learn', 'joblib']...\n",
      "   âœ… Cleanup complete.\n",
      "   - Installing new: numpy==1.26.4 ...\n",
      "   - Installing new: pandas==2.2.0 ...\n",
      "   - Installing new: scikit-learn==1.4.0 ...\n",
      "   - Installing new: matplotlib ...\n",
      "   - Installing new: seaborn ...\n",
      "   - Installing new: joblib ...\n",
      "   - Installing new: wandb ...\n",
      "âœ… [INIT] Fresh dependencies installed.\n",
      "\n",
      "ğŸ”„ [IMPORT] Loading ML libraries...\n",
      "âœ… [IMPORT] src.data_processor loaded.\n",
      "\n",
      "--- 1. Data Loading ---\n",
      "DATA_DIAG: Target data directory: /opt/ml/input/data/train\n",
      "DATA_DIAG: Full file path: /opt/ml/input/data/train/sleep_data.csv\n",
      "--- INFO: Loading data from /opt/ml/input/data/train/sleep_data.csv ---\n",
      "--- INFO: Data loaded. Shape: (374, 13) ---\n",
      "--- DEBUG: Columns standardized. ---\n",
      "--- DEBUG: Imputing 8 numerical features (Median) ---\n",
      "--- DEBUG: Imputing 5 categorical features ('Missing') ---\n",
      "--- DEBUG: BMI categories normalized. ---\n",
      "--- INFO: Data cleaning completed. Final shape: (374, 13) ---\n",
      "DATA_DIAG: Data Loaded. Shape: (374, 13)\n",
      "\n",
      "--- 2. Training ---\n",
      "STATUS: Selected Random Forest model.\n",
      "STATUS: Model fitting completed.\n",
      "\n",
      "--- 3. Evaluation & Saving ---\n",
      "âœ… Accuracy: 0.8800\n",
      "âœ… FINAL: Model saved to /opt/ml/model\n",
      "\n",
      "--- ğŸ SCRIPT FINISHING ---\n",
      "INFO: Initiating log upload procedure...\n",
      "\n",
      "============================================================\n",
      "âœ… [Log Fetcher] End of remote log.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sagemaker\n",
    "\n",
    "# ==========================================\n",
    "# ğŸ› ï¸ è¾…åŠ©å‡½æ•°å®šä¹‰\n",
    "# ==========================================\n",
    "\n",
    "def get_tuning_job_status(tuner_obj):\n",
    "    \"\"\"è·å– Tuner å½“å‰ Job çš„çŠ¶æ€\"\"\"\n",
    "    try:\n",
    "        job_name = tuner_obj.latest_tuning_job.name\n",
    "        response = boto3.client('sagemaker').describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=job_name)\n",
    "        return response['HyperParameterTuningJobStatus']\n",
    "    except Exception:\n",
    "        return \"Initializing\"\n",
    "\n",
    "def fetch_latest_error_log(bucket_name, prefix=\"debug_logs/\"):\n",
    "    \"\"\"\n",
    "    [å¤±è´¥æ—¶è°ƒç”¨] ä» S3 è·å–æœ€æ–°ç”Ÿæˆçš„è°ƒè¯•æ—¥å¿—å¹¶æ‰“å°\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ” [è‡ªåŠ¨è¯Šæ–­] æ£€æµ‹åˆ°å¤±è´¥ï¼Œæ­£åœ¨ä» s3://{bucket_name}/{prefix} æ‹‰å–æœ€æ–°æ—¥å¿—...\")\n",
    "    s3 = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "        if 'Contents' not in response:\n",
    "            print(\"âš ï¸ æœªåœ¨ S3 æ‰¾åˆ°æ—¥å¿—æ–‡ä»¶ã€‚\")\n",
    "            return\n",
    "        \n",
    "        # æŒ‰æœ€åä¿®æ”¹æ—¶é—´æ’åºï¼Œå–æœ€æ–°çš„\n",
    "        files = sorted(response['Contents'], key=lambda x: x['LastModified'])\n",
    "        latest_file = files[-1]\n",
    "        key = latest_file['Key']\n",
    "        \n",
    "        print(f\"ğŸ“„ å‘ç°æœ€æ–°æ—¥å¿—: {key} (æ—¶é—´: {latest_file['LastModified']})\")\n",
    "        print(\"=\"*60)\n",
    "        file_obj = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "        print(file_obj['Body'].read().decode('utf-8')) # æ‰“å°æ—¥å¿—å†…å®¹\n",
    "        print(\"=\"*60)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æ‹‰å–æ—¥å¿—å¤±è´¥: {e}\")\n",
    "\n",
    "def print_best_model_info(tuner_obj, model_name):\n",
    "    \"\"\"\n",
    "    [æˆåŠŸæ—¶è°ƒç”¨] è·å–å¹¶æ‰“å°æœ€ä½³æ¨¡å‹çš„ S3 è·¯å¾„\n",
    "    \"\"\"\n",
    "    try:\n",
    "        best_job = tuner_obj.best_training_job()\n",
    "        if not best_job:\n",
    "            print(f\"âš ï¸ {model_name}: ä»»åŠ¡æ˜¾ç¤ºå®Œæˆï¼Œä½†æœªæ‰¾åˆ°æœ€ä½³ Training Job (å¯èƒ½æ˜¯æ‰€æœ‰å­ä»»åŠ¡éƒ½å¤±è´¥äº†)ã€‚\")\n",
    "            return\n",
    "\n",
    "        # è·å–è¯¦ç»†ä¿¡æ¯\n",
    "        desc = best_job.describe()\n",
    "        score = desc['FinalMetricDataList'][0]['Value']\n",
    "        s3_uri = desc['ModelArtifacts']['S3ModelArtifacts']\n",
    "        \n",
    "        print(f\"\\nğŸ† {model_name} è®­ç»ƒå®Œæˆï¼\")\n",
    "        print(f\"   âœ… æœ€ä½³å‡†ç¡®ç‡ (Accuracy): {score:.4f}\")\n",
    "        print(f\"   ğŸ’¾ æœ€ä½³æ¨¡å‹ä¿å­˜ä½ç½®: {s3_uri}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ è·å– {model_name} æ¨¡å‹ä¿¡æ¯å¤±è´¥: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# ğŸš€ ä¸»æµç¨‹ï¼šå¹¶è¡Œå¯åŠ¨\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n--- ğŸš€ Step 5: Launching All Tuning Jobs in Parallel (Smart Monitor) ---\")\n",
    "print(f\"ğŸ•’ å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}\\n\")\n",
    "\n",
    "# 1. å¯åŠ¨ Random Forest\n",
    "print(f\"ğŸŒ² [1/3] Launching Random Forest...\", end=\" \")\n",
    "rf_tuner.fit({'train': train_input}, wait=False) \n",
    "print(f\"âœ… Job ID: {rf_tuner.latest_tuning_job.name}\")\n",
    "\n",
    "# 2. å¯åŠ¨ SVM\n",
    "print(f\"ğŸ›¡ï¸ [2/3] Launching SVM...\", end=\" \")\n",
    "svm_tuner.fit({'train': train_input}, wait=False)\n",
    "print(f\"âœ… Job ID: {svm_tuner.latest_tuning_job.name}\")\n",
    "\n",
    "# 3. å¯åŠ¨ Logistic Regression\n",
    "print(f\"ğŸ“ˆ [3/3] Launching Logistic Regression...\", end=\" \")\n",
    "lr_tuner.fit({'train': train_input}, wait=False)\n",
    "print(f\"âœ… Job ID: {lr_tuner.latest_tuning_job.name}\")\n",
    "\n",
    "print(\"\\nâœ¨ æ‰€æœ‰ä»»åŠ¡å·²åœ¨äº‘ç«¯å¹¶è¡Œè¿è¡Œï¼æ­£åœ¨å¯åŠ¨æ™ºèƒ½ç›‘æ§é¢æ¿...\\n\")\n",
    "print(\"-\" * 90)\n",
    "print(f\"{'Time':<10} | {'Random Forest':<20} | {'SVM':<20} | {'Logistic Regression':<20}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "# ==========================================\n",
    "# ğŸ•µï¸ å®æ—¶ç›‘æ§å¾ªç¯ (åŒ…å«ç»“æœå¤„ç†)\n",
    "# ==========================================\n",
    "\n",
    "# ç”¨äºè®°å½•å“ªäº›ä»»åŠ¡å·²ç»å¤„ç†è¿‡ï¼ˆæ‰“å°è¿‡ç»“æœï¼‰ï¼Œé¿å…é‡å¤æ‰“å°\n",
    "processed_jobs = {'RF': False, 'SVM': False, 'LR': False}\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # 1. è·å–æœ€æ–°çŠ¶æ€\n",
    "        rf_st = get_tuning_job_status(rf_tuner)\n",
    "        svm_st = get_tuning_job_status(svm_tuner)\n",
    "        lr_st = get_tuning_job_status(lr_tuner)\n",
    "        \n",
    "        current_time = datetime.now().strftime('%H:%M:%S')\n",
    "        print(f\"{current_time:<10} | {rf_st:<20} | {svm_st:<20} | {lr_st:<20}\")\n",
    "        \n",
    "        # 2. æ£€æŸ¥ RF ç»“æœ\n",
    "        if rf_st in ['Completed', 'Failed', 'Stopped'] and not processed_jobs['RF']:\n",
    "            if rf_st == 'Completed':\n",
    "                print_best_model_info(rf_tuner, \"Random Forest\")\n",
    "            elif rf_st == 'Failed':\n",
    "                print(f\"\\nâŒ Random Forest ä»»åŠ¡å¤±è´¥ï¼\")\n",
    "                fetch_latest_error_log(bucket_name)\n",
    "            processed_jobs['RF'] = True # æ ‡è®°ä¸ºå·²å¤„ç†\n",
    "\n",
    "        # 3. æ£€æŸ¥ SVM ç»“æœ\n",
    "        if svm_st in ['Completed', 'Failed', 'Stopped'] and not processed_jobs['SVM']:\n",
    "            if svm_st == 'Completed':\n",
    "                print_best_model_info(svm_tuner, \"SVM\")\n",
    "            elif svm_st == 'Failed':\n",
    "                print(f\"\\nâŒ SVM ä»»åŠ¡å¤±è´¥ï¼\")\n",
    "                fetch_latest_error_log(bucket_name)\n",
    "            processed_jobs['SVM'] = True\n",
    "\n",
    "        # 4. æ£€æŸ¥ LR ç»“æœ\n",
    "        if lr_st in ['Completed', 'Failed', 'Stopped'] and not processed_jobs['LR']:\n",
    "            if lr_st == 'Completed':\n",
    "                print_best_model_info(lr_tuner, \"Logistic Regression\")\n",
    "            elif lr_st == 'Failed':\n",
    "                print(f\"\\nâŒ Logistic Regression ä»»åŠ¡å¤±è´¥ï¼\")\n",
    "                fetch_latest_error_log(bucket_name)\n",
    "            processed_jobs['LR'] = True\n",
    "\n",
    "        # 5. é€€å‡ºæ¡ä»¶ï¼šæ‰€æœ‰ä»»åŠ¡éƒ½å·²å¤„ç†å®Œæ¯•\n",
    "        if all(processed_jobs.values()):\n",
    "            print(\"-\" * 90)\n",
    "            print(\"\\nğŸ‰ æ‰€æœ‰è°ƒå‚ä»»åŠ¡å·²ç»“æŸï¼\")\n",
    "            break\n",
    "            \n",
    "        time.sleep(30) # æ¯30ç§’åˆ·æ–°ä¸€æ¬¡\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nâš ï¸ ç›‘æ§å·²æ‰‹åŠ¨åœæ­¢ï¼ˆä»»åŠ¡ä»åœ¨ AWS åå°ç»§ç»­è¿è¡Œï¼‰ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8330e764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "| ğŸ“¦ æ­£åœ¨æ£€æŸ¥ç›®æ ‡å­˜å‚¨æ¡¶: sleep-disorder-mlops-bucket\n",
      "=======================================================\n",
      " - debug_logs/full_log_capture_20251203_075849.txt\n",
      " - debug_logs/sagemaker_connectivity_test_20251203072403.txt\n",
      " - debug_logs/train_failure_log_20251203_083143.txt\n",
      " - debug_logs/train_failure_log_20251203_084721.txt\n",
      " - debug_logs/train_failure_log_20251203_085633.txt\n",
      " - debug_logs/train_failure_log_20251203_090222.txt\n",
      " - debug_logs/train_failure_log_20251203_090914.txt\n",
      " - debug_logs/train_failure_log_20251203_091129.txt\n",
      " - debug_logs/train_failure_log_20251203_111130.txt\n",
      " - raw_data/sleep_data.csv\n",
      " - sagemaker-scikit-learn-2025-12-03-11-08-12-878/source/sourcedir.tar.gz\n",
      " - sagemaker-tuning-output/rf-tuning-251203-1908-001-d11209b3/output/model.tar.gz\n",
      "-------------------------------------------------------\n",
      "âœ… æ¨¡å‹æ–‡ä»¶ (.tar.gz) å­˜åœ¨çŠ¶æ€: æ˜¯\n",
      "âœ… è°ƒè¯•æ—¥å¿— (debug_logs) å­˜åœ¨çŠ¶æ€: æ˜¯\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError, ClientError\n",
    "import sys\n",
    "\n",
    "# âš ï¸ å°†ç›®æ ‡æ¡¶åç§°å›ºå®šä¸ºä½ è‡ªå·±çš„ S3 æ¡¶\n",
    "TARGET_BUCKET_NAME = 'sleep-disorder-mlops-bucket' \n",
    "\n",
    "def list_target_bucket_files(bucket_name):\n",
    "    \"\"\"\n",
    "    åˆ—å‡ºæŒ‡å®š S3 å­˜å‚¨æ¡¶ä¸­çš„æ‰€æœ‰æ–‡ä»¶è·¯å¾„ (Key)ã€‚\n",
    "    \"\"\"\n",
    "    print(f\"\\n=======================================================\")\n",
    "    print(f\"| ğŸ“¦ æ­£åœ¨æ£€æŸ¥ç›®æ ‡å­˜å‚¨æ¡¶: {bucket_name}\")\n",
    "    print(f\"=======================================================\")\n",
    "    \n",
    "    try:\n",
    "        s3 = boto3.client('s3')\n",
    "        paginator = s3.get_paginator('list_objects_v2')\n",
    "        pages = paginator.paginate(Bucket=bucket_name)\n",
    "        \n",
    "        found_model = False\n",
    "        found_log = False\n",
    "        \n",
    "        for page in pages:\n",
    "            contents = page.get('Contents', [])\n",
    "            if contents:\n",
    "                for obj in contents:\n",
    "                    file_key = obj['Key']\n",
    "                    print(f\" - {file_key}\")\n",
    "                    \n",
    "                    if file_key.endswith('model.tar.gz'):\n",
    "                        found_model = True\n",
    "                    if 'debug_logs/' in file_key:\n",
    "                        found_log = True\n",
    "\n",
    "        print(f\"-------------------------------------------------------\")\n",
    "        print(f\"âœ… æ¨¡å‹æ–‡ä»¶ (.tar.gz) å­˜åœ¨çŠ¶æ€: {'æ˜¯' if found_model else 'å¦'}\")\n",
    "        print(f\"âœ… è°ƒè¯•æ—¥å¿— (debug_logs) å­˜åœ¨çŠ¶æ€: {'æ˜¯' if found_log else 'å¦'}\")\n",
    "            \n",
    "    except ClientError as e:\n",
    "        error_code = e.response['Error']['Code']\n",
    "        print(f\"âŒ é”™è¯¯ï¼šæ— æ³•è®¿é—®å­˜å‚¨æ¡¶ {bucket_name}ã€‚é”™è¯¯ä»£ç : {error_code}ã€‚è¯·æ£€æŸ¥æƒé™ã€‚\", file=sys.stderr)\n",
    "    except NoCredentialsError:\n",
    "        print(\"âŒ è‡´å‘½é”™è¯¯ï¼šæ‰¾ä¸åˆ° AWS å‡­è¯ã€‚\", file=sys.stderr)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}\", file=sys.stderr)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    list_target_bucket_files(TARGET_BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff694f65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
