{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d38af7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- âš™ï¸ Step 1: Initializing SageMaker Environment ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Couldn't call 'get_role' to get Role ARN from role name ML_Project to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ è­¦å‘Š: æ— æ³•è‡ªåŠ¨è·å–è§’è‰²ï¼Œè¯·æ‰‹åŠ¨å¡«å…¥ ARNã€‚\n",
      "âœ… Role: arn:aws:iam::137568342316:role/SageMakerExecutionRole\n",
      "âœ… Bucket: sleep-disorder-mlops-bucket\n",
      "âœ… Git Repo: https://github.com/vinnie071015/sleeping-disorder-mlops.git\n",
      "\n",
      "--- ğŸ’¾ Step 2: Defining S3 Data Input ---\n",
      "âœ… Training Data Source: s3://sleep-disorder-mlops-bucket/raw_data/\n",
      "\n",
      "--- ğŸ—ï¸ Step 3: Defining Common Estimator Configuration (Git Mode) ---\n",
      "âœ… Instance Type: ml.m5.large\n",
      "âœ… Path Correction: source_dir='.', entry_point='src/train.py'\n",
      "\n",
      "--- ğŸ›ï¸ Step 4: Defining Tuners for 3 Models ---\n",
      "âœ… Tuners for RF, SVM, and LR are ready.\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, CategoricalParameter, HyperparameterTuner\n",
    "from sagemaker import get_execution_role\n",
    "import os\n",
    "\n",
    "print(\"--- âš™ï¸ Step 1: Initializing SageMaker Environment ---\")\n",
    "\n",
    "# 1. è·å–æ‰§è¡Œè§’è‰² (IAM Role)\n",
    "# å¦‚æœåœ¨æœ¬åœ° VS Code è¿è¡Œï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨æŒ‡å®š Role ARN\n",
    "try:\n",
    "    role = get_execution_role()\n",
    "except ValueError:\n",
    "    print(\"âš ï¸ è­¦å‘Š: æ— æ³•è‡ªåŠ¨è·å–è§’è‰²ï¼Œè¯·æ‰‹åŠ¨å¡«å…¥ ARNã€‚\")\n",
    "    # è¯·å» AWS Console -> IAM -> Roles æ‰¾ä¸€ä¸ªç±»ä¼¼ AmazonSageMaker-ExecutionRole çš„è§’è‰²\n",
    "    role = \"arn:aws:iam::137568342316:role/SageMakerExecutionRole\" \n",
    "\n",
    "# 2. åŸºç¡€é…ç½®\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = 'sleep-disorder-mlops-bucket' # æ‚¨çš„ S3 æ¡¶å\n",
    "\n",
    "# 3. æŒ‡å®šä»£ç æº (Source of Truth for Code)\n",
    "# SageMaker ä¼šè‡ªåŠ¨ `git clone` è¿™ä¸ªä»“åº“åˆ°è®­ç»ƒå®ä¾‹ä¸­\n",
    "git_repo = 'https://github.com/vinnie071015/sleeping-disorder-mlops.git' # æ›¿æ¢ä¸ºæ‚¨çš„ä»“åº“åœ°å€\n",
    "git_config = {\n",
    "    'repo': git_repo, \n",
    "    'branch': 'main'\n",
    "}\n",
    "\n",
    "print(f\"âœ… Role: {role}\")\n",
    "print(f\"âœ… Bucket: {bucket_name}\")\n",
    "print(f\"âœ… Git Repo: {git_repo}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n--- ğŸ’¾ Step 2: Defining S3 Data Input ---\")\n",
    "\n",
    "# å®šä¹‰ S3 æ•°æ®è¾“å…¥\n",
    "# SageMaker ä¼šè‡ªåŠ¨æŠŠè¿™ä¸ª S3 è·¯å¾„ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ä¸‹è½½åˆ°å®¹å™¨å†…çš„ /opt/ml/input/data/train/\n",
    "# è¿™é‡Œçš„ s3_data å¿…é¡»æŒ‡å‘åŒ…å« sleep_data.csv çš„æ–‡ä»¶å¤¹è·¯å¾„ (ä»¥ / ç»“å°¾)\n",
    "s3_input_path = f's3://{bucket_name}/raw_data/'\n",
    "\n",
    "train_input = sagemaker.inputs.TrainingInput(\n",
    "    s3_data=s3_input_path, \n",
    "    content_type='text/csv'\n",
    ")\n",
    "\n",
    "print(f\"âœ… Training Data Source: {s3_input_path}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n--- ğŸ—ï¸ Step 3: Defining Common Estimator Configuration (Git Mode) ---\")\n",
    "\n",
    "# ä½¿ç”¨ ml.m5.large (é€šç”¨å‹)\n",
    "instance_type = 'ml.m5.large'\n",
    "\n",
    "common_estimator_args = {\n",
    "    # ä¿®æ­£ 1: å…¥å£æ–‡ä»¶è·¯å¾„è¦åŒ…å« src (å› ä¸º source_dir å˜æˆäº†æ ¹ç›®å½•)\n",
    "    'entry_point': 'src/train.py',\n",
    "    \n",
    "    # ä¿®æ­£ 2: source_dir è®¾ä¸º '.' (ä»£è¡¨ Git ä»“åº“çš„æ ¹ç›®å½•)\n",
    "    # è¿™æ · SageMaker èƒ½åŒæ—¶çœ‹åˆ° src/ æ–‡ä»¶å¤¹å’Œ requirements.txt\n",
    "    'source_dir': '.',\n",
    "    \n",
    "    'role': role,\n",
    "    'instance_count': 1,\n",
    "    'instance_type': instance_type,\n",
    "    'framework_version': '1.2-1',\n",
    "    'py_version': 'py3',\n",
    "    'git_config': git_config,\n",
    "    'sagemaker_session': sagemaker_session,\n",
    "    \n",
    "    # ä¿®æ­£ 3: ä¸éœ€è¦æ‰‹åŠ¨æŒ‡å®š dependencies äº†\n",
    "    # å› ä¸º requirements.txt å°±åœ¨ source_dir (æ ¹ç›®å½•) ä¸‹ï¼ŒSageMaker ä¼šè‡ªåŠ¨è¯†åˆ«å¹¶å®‰è£…\n",
    "    # 'dependencies': [...] <--- åˆ é™¤è¿™è¡Œ\n",
    "}\n",
    "\n",
    "print(f\"âœ… Instance Type: {instance_type}\")\n",
    "print(f\"âœ… Path Correction: source_dir='.', entry_point='src/train.py'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n--- ğŸ›ï¸ Step 4: Defining Tuners for 3 Models ---\")\n",
    "\n",
    "# å®šä¹‰æŒ‡æ ‡æŠ“å–è§„åˆ™ (å¯¹åº” src/train.py ä¸­çš„ print è¯­å¥)\n",
    "metric_definitions = [\n",
    "    {'Name': 'accuracy', 'Regex': 'âœ… Accuracy: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'f1', 'Regex': 'âœ… F1 Score: ([0-9\\\\.]+)'}\n",
    "]\n",
    "\n",
    "# ==========================================\n",
    "# A. Random Forest Tuner\n",
    "# ==========================================\n",
    "rf_estimator = SKLearn(**common_estimator_args)\n",
    "# å›ºå®šæ¨¡å‹ç±»å‹ä¸º RF\n",
    "rf_estimator.set_hyperparameters(model_type='random_forest')\n",
    "\n",
    "rf_tuner = HyperparameterTuner(\n",
    "    estimator=rf_estimator,\n",
    "    objective_metric_name='accuracy',\n",
    "    metric_definitions=metric_definitions,\n",
    "    hyperparameter_ranges={\n",
    "        'n_estimators': IntegerParameter(50, 150),\n",
    "        'max_depth': IntegerParameter(5, 15)\n",
    "    },\n",
    "    max_jobs=2,          # æ€»å…±è·‘ 2 æ¬¡ (çœé’±)\n",
    "    max_parallel_jobs=1, # ä¸²è¡Œè·‘ (å®‰å…¨)\n",
    "    base_tuning_job_name='rf-tuning'\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# B. SVM Tuner\n",
    "# ==========================================\n",
    "svm_estimator = SKLearn(**common_estimator_args)\n",
    "svm_estimator.set_hyperparameters(model_type='svm')\n",
    "\n",
    "svm_tuner = HyperparameterTuner(\n",
    "    estimator=svm_estimator,\n",
    "    objective_metric_name='accuracy',\n",
    "    metric_definitions=metric_definitions,\n",
    "    hyperparameter_ranges={\n",
    "        'C': ContinuousParameter(0.1, 5.0),\n",
    "        'kernel': CategoricalParameter(['rbf', 'linear'])\n",
    "    },\n",
    "    max_jobs=2,\n",
    "    max_parallel_jobs=1,\n",
    "    base_tuning_job_name='svm-tuning'\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# C. Logistic Regression Tuner\n",
    "# ==========================================\n",
    "lr_estimator = SKLearn(**common_estimator_args)\n",
    "lr_estimator.set_hyperparameters(model_type='logistic_regression')\n",
    "\n",
    "lr_tuner = HyperparameterTuner(\n",
    "    estimator=lr_estimator,\n",
    "    objective_metric_name='accuracy',\n",
    "    metric_definitions=metric_definitions,\n",
    "    hyperparameter_ranges={\n",
    "        'C': ContinuousParameter(0.1, 5.0)\n",
    "    },\n",
    "    max_jobs=2,\n",
    "    max_parallel_jobs=1,\n",
    "    base_tuning_job_name='lr-tuning'\n",
    ")\n",
    "\n",
    "print(\"âœ… Tuners for RF, SVM, and LR are ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eae4aaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ğŸš€ Step 5: Launching Jobs Sequentially ---\n",
      "\n",
      "ğŸŒ² [1/3] Launching Random Forest Tuning... (Timestamp: 10:38:31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '/var/folders/py/wsw9dv2n5g70rl8sm3pxxjg40000gn/T/tmphzjps5_c'...\n",
      "Already on 'main'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your branch is up to date with 'origin/main'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....................................................*\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for HyperParameterTuning job rf-tuning-251203-1038: Failed. Reason: All training jobs failed. Please take a look at the training jobs failures to get more details.. Check troubleshooting guide for common errors: https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/py/wsw9dv2n5g70rl8sm3pxxjg40000gn/T/ipykernel_85434/1943249051.py\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nğŸŒ² [1/3] Launching Random Forest Tuning... (Timestamp: {time.strftime('%H:%M:%S')})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# SageMaker ä¼šè‡ªåŠ¨ç”Ÿæˆå”¯ä¸€çš„ Job Nameï¼Œè¿™é‡Œ fit ä¼šç›´æ¥æ‰“å°å‡ºæ¥\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrf_tuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"âœ… Random Forest Tuning Completed!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlops-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline_context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_StepArguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrieve_caller_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlops-env/lib/python3.9/site-packages/sagemaker/tuner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, job_name, include_cls_metadata, estimator_kwargs, wait, **kwargs)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_tuning_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit_with_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_cls_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlops-env/lib/python3.9/site-packages/sagemaker/tuner.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2352\u001b[0m         \u001b[0;34m\"\"\"Placeholder docstring.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2353\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_tuning_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlops-env/lib/python3.9/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mwait_for_tuning_job\u001b[0;34m(self, job, poll)\u001b[0m\n\u001b[1;32m   5363\u001b[0m         \"\"\"\n\u001b[1;32m   5364\u001b[0m         \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wait_until\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_tuning_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5365\u001b[0;31m         \u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperParameterTuningJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlops-env/lib/python3.9/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   8609\u001b[0m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8610\u001b[0m             )\n\u001b[0;32m-> 8611\u001b[0;31m         raise exceptions.UnexpectedStatusException(\n\u001b[0m\u001b[1;32m   8612\u001b[0m             \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8613\u001b[0m             \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for HyperParameterTuning job rf-tuning-251203-1038: Failed. Reason: All training jobs failed. Please take a look at the training jobs failures to get more details.. Check troubleshooting guide for common errors: https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"\\n--- ğŸš€ Step 5: Launching Jobs Sequentially ---\")\n",
    "\n",
    "# 1. è¿è¡Œ Random Forest\n",
    "print(f\"\\nğŸŒ² [1/3] Launching Random Forest Tuning... (Timestamp: {time.strftime('%H:%M:%S')})\")\n",
    "# SageMaker ä¼šè‡ªåŠ¨ç”Ÿæˆå”¯ä¸€çš„ Job Nameï¼Œè¿™é‡Œ fit ä¼šç›´æ¥æ‰“å°å‡ºæ¥\n",
    "rf_tuner.fit({'train': train_input}, wait=True) \n",
    "print(\"âœ… Random Forest Tuning Completed!\")\n",
    "\n",
    "# 2. è¿è¡Œ SVM\n",
    "print(f\"\\nğŸ›¡ï¸ [2/3] Launching SVM Tuning... (Timestamp: {time.strftime('%H:%M:%S')})\")\n",
    "svm_tuner.fit({'train': train_input}, wait=True)\n",
    "print(\"âœ… SVM Tuning Completed!\")\n",
    "\n",
    "# 3. è¿è¡Œ Logistic Regression\n",
    "print(f\"\\nğŸ“ˆ [3/3] Launching Logistic Regression Tuning... (Timestamp: {time.strftime('%H:%M:%S')})\")\n",
    "lr_tuner.fit({'train': train_input}, wait=True)\n",
    "print(\"âœ… Logistic Regression Tuning Completed!\")\n",
    "\n",
    "print(\"\\nğŸ‰ All experiments finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5061ccbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing debug_logger_test.py\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "# ==========================================\n",
    "# ğŸ› ï¸ Helper: Auto-fetch logs from S3\n",
    "# ==========================================\n",
    "def fetch_and_print_latest_log(bucket_name, prefix=\"debug_logs/\"):\n",
    "    \"\"\"\n",
    "    Connects to S3, finds the most recently modified file in the debug_logs folder,\n",
    "    and prints its content to this notebook/terminal.\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ” [Log Fetcher] Looking for logs in s3://{bucket_name}/{prefix} ...\")\n",
    "    \n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        # List objects in the debug folder\n",
    "        response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "        \n",
    "        if 'Contents' not in response:\n",
    "            print(\"âš ï¸ [Log Fetcher] No log files found in S3 yet. The container might have failed before running the script.\")\n",
    "            return\n",
    "\n",
    "        # Sort files by LastModified (newest last)\n",
    "        files = sorted(response['Contents'], key=lambda x: x['LastModified'])\n",
    "        latest_file = files[-1]\n",
    "        key = latest_file['Key']\n",
    "        \n",
    "        print(f\"ğŸ“„ [Log Fetcher] Found latest log: {key} (Last Modified: {latest_file['LastModified']})\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Download and print content\n",
    "        file_obj = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "        log_content = file_obj['Body'].read().decode('utf-8')\n",
    "        print(log_content)\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        print(\"âœ… [Log Fetcher] End of remote log.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ [Log Fetcher] Error retrieving logs: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# ğŸš€ Execution Flow\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n--- ğŸš€ Step 5: Launching Single Debug Job ---\")\n",
    "\n",
    "# Modify RF Tuner to be very minimal for debugging\n",
    "# We force it to run ONLY 1 job to save time/money\n",
    "rf_tuner.max_jobs = 1\n",
    "rf_tuner.max_parallel_jobs = 1\n",
    "\n",
    "print(f\"\\nğŸŒ² Launching Random Forest (Debug Mode: 1 Job)... (Timestamp: {time.strftime('%H:%M:%S')})\")\n",
    "\n",
    "try:\n",
    "    # We use wait=True to block here until it finishes (or fails)\n",
    "    rf_tuner.fit({'train': train_input}, wait=True)\n",
    "    print(\"âœ… Training Job Completed Successfully.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâš ï¸ Training Job Encountered an Exception (Expected during debugging): {e}\")\n",
    "\n",
    "finally:\n",
    "    # This block runs NO MATTER WHAT (Success or Failure)\n",
    "    print(\"\\n\\nâ³ Waiting 10 seconds for S3 consistency...\")\n",
    "    time.sleep(10) \n",
    "    \n",
    "    # Call the fetcher\n",
    "    fetch_and_print_latest_log(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c66268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Submitting Log Capture Test Job...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-scikit-learn-2025-12-03-07-56-36-553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-03 07:56:41 Starting - Starting the training job...\n",
      "2025-12-03 07:57:17 Downloading - Downloading input data...\n",
      "2025-12-03 07:57:42 Downloading - Downloading the training image......\n",
      "2025-12-03 07:58:54 Training - Training image download completed. Training in progress.\n",
      "2025-12-03 07:58:54 Uploading - Uploading generated training model...\n",
      "2025-12-03 07:59:06 Completed - Training job completed\n",
      "..Training seconds: 109\n",
      "Billable seconds: 109\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dd4c18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
