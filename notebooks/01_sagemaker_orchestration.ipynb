{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d38af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, CategoricalParameter, HyperparameterTuner\n",
    "from sagemaker import get_execution_role\n",
    "import os\n",
    "\n",
    "print(\"--- ‚öôÔ∏è Step 1: Initializing SageMaker Environment ---\")\n",
    "\n",
    "# 1. Get execution role (IAM Role)\n",
    "# If running locally in VS Code, the Role ARN may need to be specified manually\n",
    "try:\n",
    "    role = get_execution_role()\n",
    "except ValueError:\n",
    "    print(\"‚ö†Ô∏è Warning: Could not automatically retrieve role, please manually enter ARN.\")\n",
    "    # Please go to AWS Console -> IAM -> Roles to find a role similar to AmazonSageMaker-ExecutionRole\n",
    "    role = \"arn:aws:iam::137568342316:role/SageMakerExecutionRole\" \n",
    "\n",
    "# 2. Basic configuration\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = 'sleep-disorder-mlops-bucket' # Your S3 bucket name\n",
    "\n",
    "# 3. Specify code source (Source of Truth for Code)\n",
    "# SageMaker will automatically `git clone` this repository onto the training instance\n",
    "git_repo = 'https://github.com/vinnie071015/sleeping-disorder-mlops.git' # Replace with your repository address\n",
    "git_config = {\n",
    "    'repo': git_repo, \n",
    "    'branch': 'main'\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Role: {role}\")\n",
    "print(f\"‚úÖ Bucket: {bucket_name}\")\n",
    "print(f\"‚úÖ Git Repo: {git_repo}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- üíæ Step 2: Defining S3 Data Input ---\")\n",
    "\n",
    "# Define S3 data input\n",
    "# SageMaker will automatically download all files under this S3 path to /opt/ml/input/data/train/ inside the container\n",
    "# The s3_data here must point to the folder path containing sleep_data.csv (ending with /)\n",
    "s3_input_path = f's3://{bucket_name}/raw_data/'\n",
    "\n",
    "train_input = sagemaker.inputs.TrainingInput(\n",
    "    s3_data=s3_input_path, \n",
    "    content_type='text/csv'\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Training Data Source: {s3_input_path}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- üèóÔ∏è Step 3: Defining Common Estimator Configuration (Git Mode) ---\")\n",
    "\n",
    "# Use ml.m5.large (General Purpose)\n",
    "instance_type = 'ml.m5.large'\n",
    "\n",
    "# ‚ö†Ô∏è Critical fix: Define S3 model output path, force use of your custom bucket\n",
    "model_output_s3_path = f's3://{bucket_name}/sagemaker-tuning-output/' \n",
    "print(f\"‚úÖ Model Artifacts Output Path (FIXED): {model_output_s3_path}\")\n",
    "\n",
    "\n",
    "common_estimator_args = {\n",
    "    # Fix 1: Entry file path must include src (because source_dir became the root)\n",
    "    'entry_point': 'src/train.py',\n",
    "    \n",
    "    # Fix 2: source_dir is set to '.' (representing the root of the Git repository)\n",
    "    'source_dir': '.',\n",
    "    \n",
    "    'role': role,\n",
    "    'instance_count': 1,\n",
    "    'instance_type': instance_type,\n",
    "    'framework_version': '1.2-1',\n",
    "    'py_version': 'py3',\n",
    "    'git_config': git_config,\n",
    "    'sagemaker_session': sagemaker_session,\n",
    "    \n",
    "    # === Critical fix: Add output_path parameter ===\n",
    "    'output_path': model_output_s3_path,\n",
    "    'environment': {\n",
    "        'WANDB_API_KEY': \"0f759a15e3c54016f3f727c9720f0c9206fdd5c1\",  # The container will automatically read this variable for login\n",
    "        'WANDB_PROJECT': 'sleep-disorder-mlops', # Optional: specify project name\n",
    "        'WANDB_WATCH': 'false' # Optional: turn off unnecessary model monitoring to speed up\n",
    "    }\n",
    "    # ========================================\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Instance Type: {instance_type}\")\n",
    "print(f\"‚úÖ Path Correction: source_dir='.', entry_point='src/train.py'\")\n",
    "\n",
    "\n",
    "print(\"\\n--- üéõÔ∏è Step 4: Defining Tuners for 3 Models ---\")\n",
    "\n",
    "# Define metric capture rules (corresponds to the print statements in src/train.py)\n",
    "metric_definitions = [\n",
    "    {'Name': 'accuracy', 'Regex': '‚úÖ Accuracy: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'f1', 'Regex': '‚úÖ F1 Score: ([0-9\\\\.]+)'}\n",
    "]\n",
    "\n",
    "# ==========================================\n",
    "# A. Random Forest Tuner\n",
    "# ==========================================\n",
    "# Note: The common_estimator_args used here already includes output_path\n",
    "rf_estimator = SKLearn(**common_estimator_args) \n",
    "# Fix model type to RF\n",
    "rf_estimator.set_hyperparameters(model_type='random_forest')\n",
    "\n",
    "rf_tuner = HyperparameterTuner(\n",
    "    estimator=rf_estimator,\n",
    "    objective_metric_name='accuracy',\n",
    "    metric_definitions=metric_definitions,\n",
    "    hyperparameter_ranges={\n",
    "        'n_estimators': IntegerParameter(50, 150),\n",
    "        'max_depth': IntegerParameter(5, 15)\n",
    "    },\n",
    "    max_jobs=2,          # Run 2 jobs in total (for cost saving)\n",
    "    max_parallel_jobs=1, # Run sequentially (for safety)\n",
    "    base_tuning_job_name='rf-tuning'\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# B. SVM Tuner\n",
    "# ==========================================\n",
    "svm_estimator = SKLearn(**common_estimator_args)\n",
    "svm_estimator.set_hyperparameters(model_type='svm')\n",
    "\n",
    "svm_tuner = HyperparameterTuner(\n",
    "    estimator=svm_estimator,\n",
    "    objective_metric_name='accuracy',\n",
    "    metric_definitions=metric_definitions,\n",
    "    hyperparameter_ranges={\n",
    "        'C': ContinuousParameter(0.1, 5.0),\n",
    "        'kernel': CategoricalParameter(['rbf', 'linear'])\n",
    "    },\n",
    "    max_jobs=2,\n",
    "    max_parallel_jobs=1,\n",
    "    base_tuning_job_name='svm-tuning'\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# C. Logistic Regression Tuner\n",
    "# ==========================================\n",
    "lr_estimator = SKLearn(**common_estimator_args)\n",
    "lr_estimator.set_hyperparameters(model_type='logistic_regression')\n",
    "\n",
    "lr_tuner = HyperparameterTuner(\n",
    "    estimator=lr_estimator,\n",
    "    objective_metric_name='accuracy',\n",
    "    metric_definitions=metric_definitions,\n",
    "    hyperparameter_ranges={\n",
    "        'C': ContinuousParameter(0.1, 5.0)\n",
    "    },\n",
    "    max_jobs=2,\n",
    "    max_parallel_jobs=1,\n",
    "    base_tuning_job_name='lr-tuning'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Tuners for RF, SVM, and LR are ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5061ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sagemaker\n",
    "\n",
    "# ==========================================\n",
    "# üõ†Ô∏è Helper function definitions (Bug fixed)\n",
    "# ==========================================\n",
    "\n",
    "def get_tuning_job_status(tuner_obj):\n",
    "    \"\"\"Get the status of the current Job from the Tuner\"\"\"\n",
    "    try:\n",
    "        job_name = tuner_obj.latest_tuning_job.name\n",
    "        response = boto3.client('sagemaker').describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=job_name)\n",
    "        return response['HyperParameterTuningJobStatus']\n",
    "    except Exception:\n",
    "        return \"Initializing\"\n",
    "\n",
    "def fetch_latest_error_log(bucket_name, prefix=\"debug_logs/\"):\n",
    "    \"\"\"[Call on failure] Retrieve the latest debug log generated from S3 and print it\"\"\"\n",
    "    print(f\"\\nüîç [Automatic Diagnosis] Failure detected, retrieving latest log from s3://{bucket_name}/{prefix}...\")\n",
    "    s3 = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "        if 'Contents' not in response:\n",
    "            print(\"‚ö†Ô∏è No log file found in S3.\")\n",
    "            return\n",
    "        files = sorted(response['Contents'], key=lambda x: x['LastModified'])\n",
    "        latest_file = files[-1]\n",
    "        key = latest_file['Key']\n",
    "        print(f\"üìÑ Latest log found: {key} (Time: {latest_file['LastModified']})\")\n",
    "        print(\"=\"*60)\n",
    "        file_obj = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "        print(file_obj['Body'].read().decode('utf-8')) \n",
    "        print(\"=\"*60)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to retrieve log: {e}\")\n",
    "\n",
    "def print_best_model_info(tuner_obj, model_name):\n",
    "    \"\"\"\n",
    "    [Call on success] Retrieve and print the S3 path of the best model\n",
    "    (Fixed the issue with 'str' object has no attribute 'describe')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Get the name of the best Job\n",
    "        best_job_name = tuner_obj.best_training_job()\n",
    "        \n",
    "        if not best_job_name:\n",
    "            print(f\"‚ö†Ô∏è {model_name}: Task showed completion, but no best Training Job was found.\")\n",
    "            return\n",
    "\n",
    "        # 2. Use boto3 to query Job details directly (This is the most robust method)\n",
    "        sm_client = boto3.client('sagemaker')\n",
    "        desc = sm_client.describe_training_job(TrainingJobName=best_job_name)\n",
    "        \n",
    "        # 3. Extract metrics\n",
    "        metrics = desc.get('FinalMetricDataList', [])\n",
    "        # Find the Accuracy metric\n",
    "        score = \"N/A\"\n",
    "        for m in metrics:\n",
    "            if m['MetricName'] == 'accuracy':\n",
    "                score = m['Value']\n",
    "                break\n",
    "        \n",
    "        # 4. Extract S3 path\n",
    "        s3_uri = desc['ModelArtifacts']['S3ModelArtifacts']\n",
    "        \n",
    "        print(f\"\\nüèÜ {model_name} Training Completed!\")\n",
    "        print(f\"   ‚úÖ Best Accuracy: {score}\")\n",
    "        print(f\"   üíæ Best Model Save Location: {s3_uri}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to get {model_name} model information: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# üöÄ Main flow: Parallel launch\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n--- üöÄ Step 5: Launching All Tuning Jobs in Parallel (Smart Monitor V2) ---\")\n",
    "print(f\"üïí Start Time: {datetime.now().strftime('%H:%M:%S')}\\n\")\n",
    "\n",
    "# ‚ö†Ô∏è If you don't want to retrain, please comment out the following three fit lines\n",
    "# ‚ö†Ô∏è Run the monitoring loop below directly, it will capture the status of the tasks that have already finished\n",
    "rf_tuner.fit({'train': train_input}, wait=False) \n",
    "svm_tuner.fit({'train': train_input}, wait=False)\n",
    "lr_tuner.fit({'train': train_input}, wait=False)\n",
    "\n",
    "print(\"‚úÖ All tasks are running in parallel in the cloud (or are already running)! Starting smart monitoring panel...\\n\")\n",
    "print(\"-\" * 90)\n",
    "print(f\"{'Time':<10} | {'Random Forest':<20} | {'SVM':<20} | {'Logistic Regression':<20}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "# ==========================================\n",
    "# üïµÔ∏è Real-time monitoring loop (Includes result handling)\n",
    "# ==========================================\n",
    "\n",
    "processed_jobs = {'RF': False, 'SVM': False, 'LR': False}\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # 1. Get latest status\n",
    "        rf_st = get_tuning_job_status(rf_tuner)\n",
    "        svm_st = get_tuning_job_status(svm_tuner)\n",
    "        lr_st = get_tuning_job_status(lr_tuner)\n",
    "        \n",
    "        current_time = datetime.now().strftime('%H:%M:%S')\n",
    "        print(f\"{current_time:<10} | {rf_st:<20} | {svm_st:<20} | {lr_st:<20}\")\n",
    "        \n",
    "        # 2. Check RF results\n",
    "        if rf_st in ['Completed', 'Failed', 'Stopped'] and not processed_jobs['RF']:\n",
    "            if rf_st == 'Completed':\n",
    "                print_best_model_info(rf_tuner, \"Random Forest\")\n",
    "            elif rf_st == 'Failed':\n",
    "                print(f\"\\n‚ùå Random Forest Task Failed!\")\n",
    "                fetch_latest_error_log(LOG_BUCKET_NAME) # Use the bucket name variable defined earlier\n",
    "            processed_jobs['RF'] = True \n",
    "\n",
    "        # 3. Check SVM results\n",
    "        if svm_st in ['Completed', 'Failed', 'Stopped'] and not processed_jobs['SVM']:\n",
    "            if svm_st == 'Completed':\n",
    "                print_best_model_info(svm_tuner, \"SVM\")\n",
    "            elif svm_st == 'Failed':\n",
    "                print(f\"\\n‚ùå SVM Task Failed!\")\n",
    "                fetch_latest_error_log(LOG_BUCKET_NAME)\n",
    "            processed_jobs['SVM'] = True\n",
    "\n",
    "        # 4. Check LR results\n",
    "        if lr_st in ['Completed', 'Failed', 'Stopped'] and not processed_jobs['LR']:\n",
    "            if lr_st == 'Completed':\n",
    "                print_best_model_info(lr_tuner, \"Logistic Regression\")\n",
    "            elif lr_st == 'Failed':\n",
    "                print(f\"\\n‚ùå Logistic Regression Task Failed!\")\n",
    "                fetch_latest_error_log(LOG_BUCKET_NAME)\n",
    "            processed_jobs['LR'] = True\n",
    "\n",
    "        # 5. Exit condition\n",
    "        if all(processed_jobs.values()):\n",
    "            print(\"-\" * 90)\n",
    "            print(\"\\nüéâ All hyperparameter tuning tasks have finished!\")\n",
    "            break\n",
    "            \n",
    "        time.sleep(30) \n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚ö†Ô∏è Monitoring manually stopped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8330e764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "def print_best_model_info_fixed(tuner_obj, model_name):\n",
    "    try:\n",
    "        # 1. Get the name of the best Job (This is a string)\n",
    "        best_job_name = tuner_obj.best_training_job()\n",
    "        \n",
    "        if not best_job_name:\n",
    "            print(f\"‚ö†Ô∏è {model_name}: No best Training Job found (The task may not be completed or all failed).\")\n",
    "            return\n",
    "\n",
    "        # 2. Use boto3 to query details (Key fix)\n",
    "        sm_client = boto3.client('sagemaker')\n",
    "        desc = sm_client.describe_training_job(TrainingJobName=best_job_name)\n",
    "        \n",
    "        # 3. Extract accuracy\n",
    "        metrics = desc.get('FinalMetricDataList', [])\n",
    "        score = \"N/A\"\n",
    "        for m in metrics:\n",
    "            if m['MetricName'] == 'accuracy': # Ensure this matches the metric name you defined\n",
    "                score = m['Value']\n",
    "                break\n",
    "        \n",
    "        # 4. Extract S3 Model Path\n",
    "        s3_uri = desc['ModelArtifacts']['S3ModelArtifacts']\n",
    "        \n",
    "        print(f\"\\nüèÜ {model_name} Result Report\")\n",
    "        print(f\"   üîπ Best Job Name: {best_job_name}\")\n",
    "        print(f\"   ‚úÖ Best Accuracy: {score}\")\n",
    "        print(f\"   üíæ Model Download Link: {s3_uri}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to retrieve {model_name} information: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# Run Remedial Report\n",
    "# ==========================================\n",
    "print(\"--- üìä Final Scorecard (Extracted from Completed Jobs) ---\")\n",
    "\n",
    "# As long as your tuner object is still in memory, this code will work\n",
    "print_best_model_info_fixed(rf_tuner, \"Random Forest\")\n",
    "print_best_model_info_fixed(svm_tuner, \"SVM\")\n",
    "print_best_model_info_fixed(lr_tuner, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff694f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import os\n",
    "import joblib\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "# Set the champion model for in-depth analysis (SVM is chosen here because it has the highest accuracy)\n",
    "BEST_JOB_NAME = \"svm-tuning-251203-2103-002-c8ccdacc\" \n",
    "MODEL_S3_URI = \"s3://sleep-disorder-mlops-bucket/sagemaker-tuning-output/svm-tuning-251203-2103-002-c8ccdacc/output/model.tar.gz\"\n",
    "\n",
    "def analyze_best_job(job_name):\n",
    "    print(f\"\\n--- üïµÔ∏è‚Äç‚ôÄÔ∏è Analyzing Champion Job: {job_name} ---\")\n",
    "    \n",
    "    client = boto3.client('sagemaker')\n",
    "    desc = client.describe_training_job(TrainingJobName=job_name)\n",
    "    \n",
    "    # 1. Extract hyperparameters\n",
    "    print(\"\\n‚úÖ Best Hyperparameter Configuration (Secret Sauce):\")\n",
    "    hps = desc['HyperParameters']\n",
    "    for k, v in hps.items():\n",
    "        # Clean up extra quotes for readability\n",
    "        clean_v = v.replace('\"', '')\n",
    "        print(f\"   - {k}: {clean_v}\")\n",
    "        \n",
    "    # 2. Extract environment used\n",
    "    image_uri = desc['AlgorithmSpecification']['TrainingImage']\n",
    "    print(f\"\\n‚úÖ Training Image: {image_uri}\")\n",
    "    \n",
    "    return desc\n",
    "\n",
    "def download_and_test_model(s3_uri):\n",
    "    print(f\"\\n--- ‚¨áÔ∏è Downloading Model for Local Verification ---\")\n",
    "    \n",
    "    local_tar = \"best_model.tar.gz\"\n",
    "    extract_dir = \"./best_model_extracted\"\n",
    "    \n",
    "    # Clean up old files\n",
    "    if os.path.exists(extract_dir):\n",
    "        shutil.rmtree(extract_dir)\n",
    "    \n",
    "    # 1. Download\n",
    "    sagemaker.s3.S3Downloader.download(s3_uri, \".\")\n",
    "    print(f\"‚úÖ Model compressed package downloaded: {local_tar}\")\n",
    "    \n",
    "    # Rename the downloaded file (S3Downloader usually keeps the original name, but here we ensure the names match)\n",
    "    # Note: sagemaker download downloads to the current directory, the file name is model.tar.gz\n",
    "    # If model.tar.gz already exists in the current directory, it will be overwritten\n",
    "    \n",
    "    # 2. Extract\n",
    "    with tarfile.open(\"model.tar.gz\", \"r:gz\") as tar:\n",
    "        tar.extractall(path=extract_dir)\n",
    "        print(f\"‚úÖ Extraction complete, directory contents: {os.listdir(extract_dir)}\")\n",
    "        \n",
    "    # 3. Load Model (Sanity Check)\n",
    "    try:\n",
    "        model_path = os.path.join(extract_dir, \"model.joblib\")\n",
    "        pipeline = joblib.load(model_path)\n",
    "        print(\"\\nüéâ Model loaded successfully!\")\n",
    "        print(f\"   - Pipeline Structure: {pipeline}\")\n",
    "        \n",
    "        # Print the specific parameters of the SVM for double confirmation\n",
    "        if 'classifier' in pipeline.named_steps:\n",
    "            clf = pipeline.named_steps['classifier']\n",
    "            print(f\"   - Classifier Parameters: {clf.get_params()}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Model loading failed: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Analyze parameters\n",
    "    analyze_best_job(BEST_JOB_NAME)\n",
    "    \n",
    "    # 2. Download and test\n",
    "    download_and_test_model(MODEL_S3_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938b314c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
