{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d38af7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/zhengchengsheng/Library/Application Support/sagemaker/config.yaml\n",
      "--- âš™ï¸ Step 1: Initializing SageMaker Environment ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name ML_Project to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ è­¦å‘Š: æ— æ³•è‡ªåŠ¨è·å–è§’è‰²ï¼Œè¯·æ‰‹åŠ¨å¡«å…¥ ARNã€‚\n",
      "âœ… Role: arn:aws:iam::137568342316:role/SageMakerExecutionRole\n",
      "âœ… Bucket: sleep-disorder-mlops-bucket\n",
      "âœ… Git Repo: https://github.com/vinnie071015/sleeping-disorder-mlops.git\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, CategoricalParameter, HyperparameterTuner\n",
    "from sagemaker import get_execution_role\n",
    "import os\n",
    "\n",
    "print(\"--- âš™ï¸ Step 1: Initializing SageMaker Environment ---\")\n",
    "\n",
    "# 1. è·å–æ‰§è¡Œè§’è‰² (IAM Role)\n",
    "# å¦‚æœåœ¨æœ¬åœ° VS Code è¿è¡Œï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨æŒ‡å®š Role ARN\n",
    "try:\n",
    "    role = get_execution_role()\n",
    "except ValueError:\n",
    "    print(\"âš ï¸ è­¦å‘Š: æ— æ³•è‡ªåŠ¨è·å–è§’è‰²ï¼Œè¯·æ‰‹åŠ¨å¡«å…¥ ARNã€‚\")\n",
    "    # è¯·å» AWS Console -> IAM -> Roles æ‰¾ä¸€ä¸ªç±»ä¼¼ AmazonSageMaker-ExecutionRole çš„è§’è‰²\n",
    "    role = \"arn:aws:iam::137568342316:role/SageMakerExecutionRole\" \n",
    "\n",
    "# 2. åŸºç¡€é…ç½®\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = 'sleep-disorder-mlops-bucket' # æ‚¨çš„ S3 æ¡¶å\n",
    "\n",
    "# 3. æŒ‡å®šä»£ç æº (Source of Truth for Code)\n",
    "# SageMaker ä¼šè‡ªåŠ¨ `git clone` è¿™ä¸ªä»“åº“åˆ°è®­ç»ƒå®ä¾‹ä¸­\n",
    "git_repo = 'https://github.com/vinnie071015/sleeping-disorder-mlops.git' # æ›¿æ¢ä¸ºæ‚¨çš„ä»“åº“åœ°å€\n",
    "git_config = {\n",
    "    'repo': git_repo, \n",
    "    'branch': 'main'\n",
    "}\n",
    "\n",
    "print(f\"âœ… Role: {role}\")\n",
    "print(f\"âœ… Bucket: {bucket_name}\")\n",
    "print(f\"âœ… Git Repo: {git_repo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebd6891b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ğŸ’¾ Step 2: Defining S3 Data Input ---\n",
      "âœ… Training Data Source: s3://sleep-disorder-mlops-bucket/raw_data/\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- ğŸ’¾ Step 2: Defining S3 Data Input ---\")\n",
    "\n",
    "# å®šä¹‰ S3 æ•°æ®è¾“å…¥\n",
    "# SageMaker ä¼šè‡ªåŠ¨æŠŠè¿™ä¸ª S3 è·¯å¾„ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ä¸‹è½½åˆ°å®¹å™¨å†…çš„ /opt/ml/input/data/train/\n",
    "# è¿™é‡Œçš„ s3_data å¿…é¡»æŒ‡å‘åŒ…å« sleep_data.csv çš„æ–‡ä»¶å¤¹è·¯å¾„ (ä»¥ / ç»“å°¾)\n",
    "s3_input_path = f's3://{bucket_name}/raw_data/'\n",
    "\n",
    "train_input = sagemaker.inputs.TrainingInput(\n",
    "    s3_data=s3_input_path, \n",
    "    content_type='text/csv'\n",
    ")\n",
    "\n",
    "print(f\"âœ… Training Data Source: {s3_input_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abdf9be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ğŸ—ï¸ Step 3: Defining Common Estimator Configuration (Git Mode) ---\n",
      "âœ… Instance Type: ml.m5.large\n",
      "âœ… Path Correction: source_dir='.', entry_point='src/train.py'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- ğŸ—ï¸ Step 3: Defining Common Estimator Configuration (Git Mode) ---\")\n",
    "\n",
    "# ä½¿ç”¨ ml.m5.large (é€šç”¨å‹)\n",
    "instance_type = 'ml.m5.large'\n",
    "\n",
    "common_estimator_args = {\n",
    "    # ä¿®æ­£ 1: å…¥å£æ–‡ä»¶è·¯å¾„è¦åŒ…å« src (å› ä¸º source_dir å˜æˆäº†æ ¹ç›®å½•)\n",
    "    'entry_point': 'src/train.py',\n",
    "    \n",
    "    # ä¿®æ­£ 2: source_dir è®¾ä¸º '.' (ä»£è¡¨ Git ä»“åº“çš„æ ¹ç›®å½•)\n",
    "    # è¿™æ · SageMaker èƒ½åŒæ—¶çœ‹åˆ° src/ æ–‡ä»¶å¤¹å’Œ requirements.txt\n",
    "    'source_dir': '.',\n",
    "    \n",
    "    'role': role,\n",
    "    'instance_count': 1,\n",
    "    'instance_type': instance_type,\n",
    "    'framework_version': '1.2-1',\n",
    "    'py_version': 'py3',\n",
    "    'git_config': git_config,\n",
    "    'sagemaker_session': sagemaker_session,\n",
    "    \n",
    "    # ä¿®æ­£ 3: ä¸éœ€è¦æ‰‹åŠ¨æŒ‡å®š dependencies äº†\n",
    "    # å› ä¸º requirements.txt å°±åœ¨ source_dir (æ ¹ç›®å½•) ä¸‹ï¼ŒSageMaker ä¼šè‡ªåŠ¨è¯†åˆ«å¹¶å®‰è£…\n",
    "    # 'dependencies': [...] <--- åˆ é™¤è¿™è¡Œ\n",
    "}\n",
    "\n",
    "print(f\"âœ… Instance Type: {instance_type}\")\n",
    "print(f\"âœ… Path Correction: source_dir='.', entry_point='src/train.py'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1098819e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ğŸ›ï¸ Step 4: Defining Tuners for 3 Models ---\n",
      "âœ… Tuners for RF, SVM, and LR are ready.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- ğŸ›ï¸ Step 4: Defining Tuners for 3 Models ---\")\n",
    "\n",
    "# å®šä¹‰æŒ‡æ ‡æŠ“å–è§„åˆ™ (å¯¹åº” src/train.py ä¸­çš„ print è¯­å¥)\n",
    "metric_definitions = [\n",
    "    {'Name': 'accuracy', 'Regex': 'âœ… Accuracy: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'f1', 'Regex': 'âœ… F1 Score: ([0-9\\\\.]+)'}\n",
    "]\n",
    "\n",
    "# ==========================================\n",
    "# A. Random Forest Tuner\n",
    "# ==========================================\n",
    "rf_estimator = SKLearn(**common_estimator_args)\n",
    "# å›ºå®šæ¨¡å‹ç±»å‹ä¸º RF\n",
    "rf_estimator.set_hyperparameters(model_type='random_forest')\n",
    "\n",
    "rf_tuner = HyperparameterTuner(\n",
    "    estimator=rf_estimator,\n",
    "    objective_metric_name='accuracy',\n",
    "    metric_definitions=metric_definitions,\n",
    "    hyperparameter_ranges={\n",
    "        'n_estimators': IntegerParameter(50, 150),\n",
    "        'max_depth': IntegerParameter(5, 15)\n",
    "    },\n",
    "    max_jobs=2,          # æ€»å…±è·‘ 2 æ¬¡ (çœé’±)\n",
    "    max_parallel_jobs=1, # ä¸²è¡Œè·‘ (å®‰å…¨)\n",
    "    base_tuning_job_name='rf-tuning'\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# B. SVM Tuner\n",
    "# ==========================================\n",
    "svm_estimator = SKLearn(**common_estimator_args)\n",
    "svm_estimator.set_hyperparameters(model_type='svm')\n",
    "\n",
    "svm_tuner = HyperparameterTuner(\n",
    "    estimator=svm_estimator,\n",
    "    objective_metric_name='accuracy',\n",
    "    metric_definitions=metric_definitions,\n",
    "    hyperparameter_ranges={\n",
    "        'C': ContinuousParameter(0.1, 5.0),\n",
    "        'kernel': CategoricalParameter(['rbf', 'linear'])\n",
    "    },\n",
    "    max_jobs=2,\n",
    "    max_parallel_jobs=1,\n",
    "    base_tuning_job_name='svm-tuning'\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# C. Logistic Regression Tuner\n",
    "# ==========================================\n",
    "lr_estimator = SKLearn(**common_estimator_args)\n",
    "lr_estimator.set_hyperparameters(model_type='logistic_regression')\n",
    "\n",
    "lr_tuner = HyperparameterTuner(\n",
    "    estimator=lr_estimator,\n",
    "    objective_metric_name='accuracy',\n",
    "    metric_definitions=metric_definitions,\n",
    "    hyperparameter_ranges={\n",
    "        'C': ContinuousParameter(0.1, 5.0)\n",
    "    },\n",
    "    max_jobs=2,\n",
    "    max_parallel_jobs=1,\n",
    "    base_tuning_job_name='lr-tuning'\n",
    ")\n",
    "\n",
    "print(\"âœ… Tuners for RF, SVM, and LR are ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eae4aaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ğŸš€ Step 5: Launching Jobs Sequentially ---\n",
      "\n",
      "ğŸŒ² [1/3] Launching Random Forest Tuning... (Timestamp: 21:51:39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '/var/folders/py/wsw9dv2n5g70rl8sm3pxxjg40000gn/T/tmp9ftsczkz'...\n",
      "Already on 'main'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your branch is up to date with 'origin/main'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................................................*\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for HyperParameterTuning job rf-tuning-251201-2151: Failed. Reason: All training jobs failed. Please take a look at the training jobs failures to get more details.. Check troubleshooting guide for common errors: https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/py/wsw9dv2n5g70rl8sm3pxxjg40000gn/T/ipykernel_74765/1943249051.py\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nğŸŒ² [1/3] Launching Random Forest Tuning... (Timestamp: {time.strftime('%H:%M:%S')})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# SageMaker ä¼šè‡ªåŠ¨ç”Ÿæˆå”¯ä¸€çš„ Job Nameï¼Œè¿™é‡Œ fit ä¼šç›´æ¥æ‰“å°å‡ºæ¥\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrf_tuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"âœ… Random Forest Tuning Completed!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlops-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline_context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_StepArguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrieve_caller_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlops-env/lib/python3.9/site-packages/sagemaker/tuner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, job_name, include_cls_metadata, estimator_kwargs, wait, **kwargs)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_tuning_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit_with_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_cls_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlops-env/lib/python3.9/site-packages/sagemaker/tuner.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2352\u001b[0m         \u001b[0;34m\"\"\"Placeholder docstring.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2353\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_tuning_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlops-env/lib/python3.9/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mwait_for_tuning_job\u001b[0;34m(self, job, poll)\u001b[0m\n\u001b[1;32m   5363\u001b[0m         \"\"\"\n\u001b[1;32m   5364\u001b[0m         \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wait_until\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_tuning_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5365\u001b[0;31m         \u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperParameterTuningJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlops-env/lib/python3.9/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   8609\u001b[0m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8610\u001b[0m             )\n\u001b[0;32m-> 8611\u001b[0;31m         raise exceptions.UnexpectedStatusException(\n\u001b[0m\u001b[1;32m   8612\u001b[0m             \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8613\u001b[0m             \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for HyperParameterTuning job rf-tuning-251201-2151: Failed. Reason: All training jobs failed. Please take a look at the training jobs failures to get more details.. Check troubleshooting guide for common errors: https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"\\n--- ğŸš€ Step 5: Launching Jobs Sequentially ---\")\n",
    "\n",
    "# 1. è¿è¡Œ Random Forest\n",
    "print(f\"\\nğŸŒ² [1/3] Launching Random Forest Tuning... (Timestamp: {time.strftime('%H:%M:%S')})\")\n",
    "# SageMaker ä¼šè‡ªåŠ¨ç”Ÿæˆå”¯ä¸€çš„ Job Nameï¼Œè¿™é‡Œ fit ä¼šç›´æ¥æ‰“å°å‡ºæ¥\n",
    "rf_tuner.fit({'train': train_input}, wait=True) \n",
    "print(\"âœ… Random Forest Tuning Completed!\")\n",
    "\n",
    "# 2. è¿è¡Œ SVM\n",
    "print(f\"\\nğŸ›¡ï¸ [2/3] Launching SVM Tuning... (Timestamp: {time.strftime('%H:%M:%S')})\")\n",
    "svm_tuner.fit({'train': train_input}, wait=True)\n",
    "print(\"âœ… SVM Tuning Completed!\")\n",
    "\n",
    "# 3. è¿è¡Œ Logistic Regression\n",
    "print(f\"\\nğŸ“ˆ [3/3] Launching Logistic Regression Tuning... (Timestamp: {time.strftime('%H:%M:%S')})\")\n",
    "lr_tuner.fit({'train': train_input}, wait=True)\n",
    "print(\"âœ… Logistic Regression Tuning Completed!\")\n",
    "\n",
    "print(\"\\nğŸ‰ All experiments finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5061ccbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ•µï¸â€â™‚ï¸ æ­£åœ¨å…¨é¢è¯Šæ–­ä»»åŠ¡: rf-tuning-251201-2151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengchengsheng/opt/anaconda3/envs/mlops-env/lib/python3.9/site-packages/boto3/compat.py:84: PythonDeprecationWarning: Boto3 will no longer support Python 3.9 starting April 29, 2026. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.10 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” æ‰«æäº†æœ€è¿‘ 2 ä¸ªå­ä»»åŠ¡...\n",
      "\n",
      "â¡ï¸ å­ä»»åŠ¡: rf-tuning-251201-2151-002-b7b6db5b | çŠ¶æ€: Failed\n",
      "\n",
      "ğŸš¨ é”å®šé¦–ä¸ªå¤±è´¥å­ä»»åŠ¡: rf-tuning-251201-2151-002-b7b6db5b\n",
      "\n",
      "âŒ æ ¸å¿ƒæŠ¥é”™ç®€è¿° (FailureReason):\n",
      "----------------------------------------\n",
      "AlgorithmError: framework error: \n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.9/site-packages/sagemaker_containers/_trainer.py\", line 84, in train\n",
      "    entrypoint()\n",
      "  File \"/miniconda3/lib/python3.9/site-packages/sagemaker_sklearn_container/training.py\", line 39, in main\n",
      "    train(environment.Environment())\n",
      "  File \"/miniconda3/lib/python3.9/site-packages/sagemaker_sklearn_container/training.py\", line 31, in train\n",
      "    entry_point.run(uri=training_environment.module_dir,\n",
      "  File \"/miniconda3/lib/python3.9/site-packages/sagemaker_training/entry_point.py\", line 108, in run\n",
      "    return runner.get(runner_type, user_entry_point, args, env_vars, extra_opts).run(\n",
      "  File \"/miniconda3/lib/python3.9/site-packages/sagemaker_training/process.py\", line 424, in run\n",
      "    process = check_error(\n",
      "  File \"/miniconda3/lib/python3.9/site-packages/sagemaker_training/process.py\", line 335, in check_error\n",
      "    raise error_class(\n",
      "sagemaker_training.errors.ExecuteUserScriptError: ExecuteUserScriptError:\n",
      "ExitCode 1\n",
      "Erro\n",
      "----------------------------------------\n",
      "ğŸ’¡ å»ºè®®: ä»£ç åœ¨å¯åŠ¨é˜¶æ®µå´©æºƒã€‚å¯èƒ½æ˜¯ä¾èµ–å†²çªæˆ– import é”™è¯¯ã€‚\n",
      "\n",
      "ğŸ“ æ­£åœ¨å°è¯•æ‹‰å– CloudWatch è¯¦ç»†å´©æºƒæ—¥å¿—...\n",
      "âš ï¸ æ— æ³•è·å–æ—¥å¿— (å¯èƒ½æ˜¯æ—¥å¿—ç»„ä¸å­˜åœ¨): An error occurred (ResourceNotFoundException) when calling the DescribeLogStreams operation: The specified log group does not exist.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "def diagnose_tuning_job(tuning_job_name=None):\n",
    "    \"\"\"\n",
    "    å…¨èƒ½è¯Šæ–­å‡½æ•°ï¼šç»“åˆäº† API çŠ¶æ€æŸ¥è¯¢å’Œ CloudWatch æ—¥å¿—æŠ“å–ã€‚\n",
    "    \"\"\"\n",
    "    # å¦‚æœæ²¡æœ‰ä¼ å…¥åå­—ï¼Œå°è¯•ä» rf_tuner è·å–\n",
    "    if tuning_job_name is None:\n",
    "        try:\n",
    "            tuning_job_name = rf_tuner.latest_tuning_job.name\n",
    "        except NameError:\n",
    "            print(\"âŒ é”™è¯¯: æœªä¼ å…¥ä»»åŠ¡åï¼Œä¸”å†…å­˜ä¸­æ‰¾ä¸åˆ° rf_tuner å¯¹è±¡ã€‚\")\n",
    "            return\n",
    "\n",
    "    print(f\"ğŸ•µï¸â€â™‚ï¸ æ­£åœ¨å…¨é¢è¯Šæ–­ä»»åŠ¡: {tuning_job_name}\")\n",
    "    \n",
    "    sm_client = boto3.client('sagemaker')\n",
    "    logs_client = boto3.client('logs')\n",
    "    \n",
    "    # 1. åˆ—å‡ºè¯¥è°ƒä¼˜ä»»åŠ¡ä¸‹çš„å­è®­ç»ƒä»»åŠ¡\n",
    "    try:\n",
    "        tuner_resp = sm_client.list_training_jobs_for_hyper_parameter_tuning_job(\n",
    "            HyperParameterTuningJobName=tuning_job_name,\n",
    "            MaxResults=10,\n",
    "            SortBy='CreationTime',\n",
    "            SortOrder='Descending'\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æ— æ³•æ‰¾åˆ°ä»»åŠ¡æˆ–æƒé™ä¸è¶³: {e}\")\n",
    "        return\n",
    "\n",
    "    jobs = tuner_resp.get('TrainingJobSummaries', [])\n",
    "    print(f\"ğŸ” æ‰«æäº†æœ€è¿‘ {len(jobs)} ä¸ªå­ä»»åŠ¡...\\n\")\n",
    "    \n",
    "    found_failure = False\n",
    "    \n",
    "    # 2. éå†å¯»æ‰¾å¤±è´¥çš„ä»»åŠ¡\n",
    "    for job in jobs:\n",
    "        job_name = job['TrainingJobName']\n",
    "        status = job['TrainingJobStatus']\n",
    "        \n",
    "        print(f\"â¡ï¸ å­ä»»åŠ¡: {job_name} | çŠ¶æ€: {status}\")\n",
    "        \n",
    "        if status == 'Failed':\n",
    "            found_failure = True\n",
    "            print(f\"\\nğŸš¨ é”å®šé¦–ä¸ªå¤±è´¥å­ä»»åŠ¡: {job_name}\")\n",
    "            \n",
    "            # --- A. è·å–ç®€çŸ­åŸå›  (SageMaker API) ---\n",
    "            detail = sm_client.describe_training_job(TrainingJobName=job_name)\n",
    "            failure_reason = detail.get('FailureReason', 'æœªçŸ¥é”™è¯¯')\n",
    "            \n",
    "            print(f\"\\nâŒ æ ¸å¿ƒæŠ¥é”™ç®€è¿° (FailureReason):\\n{'-'*40}\\n{failure_reason}\\n{'-'*40}\")\n",
    "            \n",
    "            # æ™ºèƒ½å»ºè®®\n",
    "            if \"AccessDenied\" in failure_reason or \"403\" in failure_reason:\n",
    "                print(\"ğŸ’¡ å»ºè®®: IAM è§’è‰²æƒé™ä¸è¶³ï¼Œè¯·æ£€æŸ¥æ˜¯å¦é™„åŠ äº† AmazonS3FullAccessã€‚\")\n",
    "            elif \"ModuleNotFoundError\" in failure_reason:\n",
    "                print(\"ğŸ’¡ å»ºè®®: ç¼ºå°‘ä¾èµ–åº“ã€‚è¯·æ£€æŸ¥ src/requirements.txt æ˜¯å¦åŒ…å«è¯¥åº“ï¼Œä¸”å·²æ¨é€åˆ° Gitã€‚\")\n",
    "            elif \"FileNotFoundError\" in failure_reason:\n",
    "                print(\"ğŸ’¡ å»ºè®®: S3 æ•°æ®è·¯å¾„é”™è¯¯æˆ–æ–‡ä»¶åä¸åŒ¹é…ã€‚è¯·æ£€æŸ¥ Notebook ä¸­çš„ Input Data é…ç½®ã€‚\")\n",
    "            elif \"ExecuteUserScriptError\" in failure_reason:\n",
    "                print(\"ğŸ’¡ å»ºè®®: ä»£ç åœ¨å¯åŠ¨é˜¶æ®µå´©æºƒã€‚å¯èƒ½æ˜¯ä¾èµ–å†²çªæˆ– import é”™è¯¯ã€‚\")\n",
    "            \n",
    "            # --- B. è·å–è¯¦ç»†æ—¥å¿— (CloudWatch Logs) ---\n",
    "            # åªæœ‰å½“ç®€çŸ­åŸå› çœ‹ä¸å‡ºé—®é¢˜ï¼ˆé€šå¸¸æ˜¯ AlgorithmError/ExecuteUserScriptErrorï¼‰æ—¶ï¼Œæ‰éœ€è¦çœ‹æ—¥å¿—\n",
    "            print(f\"\\nğŸ“ æ­£åœ¨å°è¯•æ‹‰å– CloudWatch è¯¦ç»†å´©æºƒæ—¥å¿—...\")\n",
    "            \n",
    "            try:\n",
    "                # è·å–æ—¥å¿—æµåç§°\n",
    "                streams = logs_client.describe_log_streams(\n",
    "                    logGroupName='/aws/sagemaker/TrainingJobs',\n",
    "                    logStreamNamePrefix=job_name\n",
    "                )\n",
    "                \n",
    "                if not streams['logStreams']:\n",
    "                    print(\"âš ï¸ è­¦å‘Š: è¯¥ä»»åŠ¡æ²¡æœ‰ç”Ÿæˆä»»ä½•æ—¥å¿—ï¼ˆå¯èƒ½åœ¨ç¯å¢ƒå‡†å¤‡é˜¶æ®µå°±æŒ‚äº†ï¼Œå¦‚ä¾èµ–å®‰è£…å¤±è´¥ï¼‰ã€‚\")\n",
    "                else:\n",
    "                    stream_name = streams['logStreams'][0]['logStreamName']\n",
    "                    # æ‹‰å–æœ€å 20 è¡Œæ—¥å¿—\n",
    "                    logs = logs_client.get_log_events(\n",
    "                        logGroupName='/aws/sagemaker/TrainingJobs',\n",
    "                        logStreamName=stream_name,\n",
    "                        startFromHead=False,\n",
    "                        limit=25\n",
    "                    )\n",
    "                    \n",
    "                    print(\"\\n\" + \"=\"*20 + \" â˜ ï¸ å´©æºƒç°åœºè¿˜åŸ (Traceback) â˜ ï¸ \" + \"=\"*20)\n",
    "                    for event in logs['events']:\n",
    "                        print(event['message'].rstrip())\n",
    "                    print(\"=\"*65)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ æ— æ³•è·å–æ—¥å¿— (å¯èƒ½æ˜¯æ—¥å¿—ç»„ä¸å­˜åœ¨): {e}\")\n",
    "            \n",
    "            break # åªè¯Šæ–­æœ€æ–°çš„ä¸€ä¸ªé”™è¯¯å³å¯\n",
    "\n",
    "    if not found_failure:\n",
    "        print(\"\\nâœ… å½“å‰æ‰«æçš„å­ä»»åŠ¡ä¸­æ²¡æœ‰å‘ç° 'Failed' çŠ¶æ€ã€‚\")\n",
    "\n",
    "# --- ä½¿ç”¨æ–¹æ³• ---\n",
    "# ç›´æ¥è¿è¡Œå³å¯ï¼Œå®ƒä¼šè‡ªåŠ¨æ‰¾ rf_tuner çš„æœ€æ–°ä»»åŠ¡\n",
    "if 'rf_tuner' in globals():\n",
    "    diagnose_tuning_job(rf_tuner.latest_tuning_job.name)\n",
    "else:\n",
    "    print(\"rf_tuner å¯¹è±¡ä¸å­˜åœ¨ï¼Œè¯·æ‰‹åŠ¨ä¼ å…¥ä»»åŠ¡åï¼Œä¾‹å¦‚: diagnose_tuning_job('rf-tuning-xxxx')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c66268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
